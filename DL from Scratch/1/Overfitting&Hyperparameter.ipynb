{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overfitting, Hyperparameter",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMREvSg3ocIrNQdQENshPJi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ownit4137/TIL/blob/main/DL%20from%20Scratch/1/Overfitting%26Hyperparameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdWCF695_-dW"
      },
      "source": [
        "# Overfitting(과적합)\r\n",
        "\r\n",
        "- 신경망이 훈련 데이터에 지나치게 적응된 것\r\n",
        "- 매개변수가 많아 표현력이 높거나, 훈련 데이터가 적을 때 발생\r\n",
        "- 훈련 데이터 정확도(accuracy)가 과도하게 높고(90% ~), 시험 데이터의 정확도가 낮음\r\n",
        "- 해결책으로 **가중치 감소, 드롭아웃** 등이 있음\r\n",
        "\r\n",
        "## Weight Decay(가중치 감소)\r\n",
        "\r\n",
        "- Overfitting은 가중치가 커져서 발생하는 경우가 많음\r\n",
        "- 손실 함수에 가중치와 관련된 식을 더해주어 역전파 시에 가중치를 추가로 규제\r\n",
        "- 주로 L1, L2, Lmax norm(항)을 추가함, 책에서는 L2 사용\r\n",
        "\r\n",
        "$L_{2} = \\cfrac{1}{2} \\sqrt{\\sum_i {w_{i}}^2 }$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1EGEq9TFHyE"
      },
      "source": [
        "def loss(self, x, t):\r\n",
        "  y = self.predict(x)\r\n",
        "\r\n",
        "  weight_decay = 0\r\n",
        "  for idx in range(1, self.hidden_layer_num + 2):\r\n",
        "    W = self.params['W' + str(idx)]\r\n",
        "    weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W ** 2)\r\n",
        "\r\n",
        "  return self.last_layer.forward(y, t) + weight_decay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzqexaMCFISc"
      },
      "source": [
        "## Dropout(드롭아웃)\r\n",
        "\r\n",
        "- [논문](http://arxiv.org/abs/1207.0580)\r\n",
        "- training 할 때 뉴런을 임의로 삭제하면서 학습하는 방법\r\n",
        "- testing에는 각 뉴런의 출력에 `1 - 노드 삭제 비율`을 곱하여 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTfGmpOQ_mzu"
      },
      "source": [
        "class Dropout:\r\n",
        "   ...\r\n",
        "\r\n",
        "    def forward(self, x, train_flg=True):\r\n",
        "        if train_flg: # train일때\r\n",
        "            # 랜덤으로 T/F 배열 생성\r\n",
        "            # *x.shape => 함수의 가변 인자\r\n",
        "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\r\n",
        "\r\n",
        "            # 무작위의 뉴런을 통과시킴\r\n",
        "            return x * self.mask\r\n",
        "        else: # test일 때\r\n",
        "            return x * (1.0 - self.dropout_ratio)\r\n",
        "\r\n",
        "    def backward(self, dout):\r\n",
        "        return dout * self.mask\r\n",
        "    ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc7KKeVEGS_T"
      },
      "source": [
        "# 하이퍼파라미터 최적화\r\n",
        "\r\n",
        "- 하이퍼파라미터는 모델 내부에서 설정되는 것이 아닌, 사용자가 설정해줘야 하는 것\r\n",
        "- 각 층의 뉴런 수, 배치 크기, 학습률, 가중치 감소 등\r\n",
        "- hyperparameter 전용 확인 데이터를 validation(검증) 데이터라고 함\r\n",
        "- log scale(10의 거듭제곱)로 대략 hyperparameter의 범위를 지정하고 학습 결과를 각각 비교\r\n",
        "- [베이지안 최적화](https://shinminyong.tistory.com/37) -> 더 효율적인 방법\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojvmg438IMRN"
      },
      "source": [
        "...\r\n",
        "\r\n",
        "# np.random.uniform : 균일한 분포\r\n",
        "weight_decay = 10 ** np.random.uniform(-8, -4)\r\n",
        "learning_rate = 10 ** np.random.uniform(-6, -2) \r\n",
        "\r\n",
        "..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyYHElcvI0bT"
      },
      "source": [
        "> A model hyperparameter is a configuration that is external to the model and whose value cannot be estimated from data. \r\n",
        "- They are often used in processes to help estimate model parameters.\r\n",
        "- They are often specified by the practitioner.\r\n",
        "- They can often be set using heuristics.\r\n",
        "- They are often tuned for a given predictive modeling problem.\r\n"
      ]
    }
  ]
}